---
import Layout from "../../../components/Layout.astro";
const BASE = import.meta.env.BASE_URL;

// Edit these strings later
const project = {
  title: "Lobster Pot Recovery System",
  subtitle: "Capstone Project for Design of Electromechanical Systems (2.017)",
  date: "May 2025",
  category: "System Design, Controls",
  tools: ["Python", "Embedded", "MAVLink", "ArduSub"],
  links: [
    { label: "Final Poster", href: "2025-DeFlorez-LobsterPotRetrievalSystem.pdf" },
    { label: "Final Paper", href: "2017-FinalPaper.pdf" }, // put report.pdf in public/projects/2017/ if you want
  ],
  // Add images later in /public/projects/2017/
gallery: [
  { src: `${BASE}projects/2017/hero-1.png`, mode: "cover" },
  { src: `${BASE}projects/2017/hero-2.png`, mode: "contain" },
  { src: `${BASE}projects/2017/hero-3.JPG`, mode: "cover" },
],

};
---

<Layout title={`${project.title} — River Adkins`}>
  <section class="panel project-page">
    <!-- ===================== -->
    <!-- Back -->
    <!-- ===================== -->
    <a class="back" href={`${import.meta.env.BASE_URL}#projects`}>← Back to projects</a>

    <!-- ===================== -->
    <!-- Header -->
    <!-- ===================== -->
    <header class="project-header">
      <h1 class="project-title">{project.title}</h1>
      <p class="project-subtitle">{project.subtitle}</p>
    </header>

    <!-- ===================== -->
    <!-- Top: Gallery + Info -->
    <!-- ===================== -->
    <div class="project-top">
      <!-- Gallery -->
      <div class="gallery" data-gallery>
        <div class="gallery-track">
          {project.gallery.map((item) => (
            <div class={`gallery-slide ${item.mode === "contain" ? "is-poster" : ""}`}>
                <img src={item.src} alt="" loading="lazy" />
            </div>
            ))}

        </div>

        <div class="gallery-controls">
        <button type="button" class="gallery-btn" data-prev aria-label="Previous">←</button>
        <button type="button" class="gallery-btn" data-next aria-label="Next">→</button>
        </div>


        <div class="gallery-dots" data-dots></div>
      </div>

      <!-- Project info card -->
      <aside class="project-card">
        <h2 class="project-card-title">Lobster Pot Recovery System</h2>
        <hr />
        <p><strong>Category:</strong> {project.category}</p>
        <p><strong>Project date:</strong> {project.date}</p>
        <p><strong>Tools used:</strong> {project.tools.join(", ")}</p>

        <div class="project-links">
          {project.links.map((l) => (
            <a
              class="link"
              href={l.href}
              target={l.href.startsWith("http") ? "_blank" : undefined}
              rel="noreferrer"
            >
              {l.label} →
            </a>
          ))}
        </div>
      </aside>
    </div>

    <!-- ===================== -->
    <!-- Body -->
    <!-- ===================== -->
    <article class="project-body">
      <!-- Project Description -->
      <section>
        <h2>Project Description</h2>

        <p>
          This project focused on designing an ROV system to autonomously retrieve lobster pots using
          GPS-based localization and a custom disengageable hook. Our team of nine developed a system
          with a BlueROV2 base platform, outfitted with acoustic and inertial navigation, a barbed
          retrieval mechanism, and autonomous driving.
        </p>

        <p>
          I worked on the controls team with one other person. Together we developed a minimal PID
          control system for testing and designed a system integrating existing software to support
          waypoint navigation and control.
        </p>

        <p>
          By the end of the semester, we wrote a paper and gave a 45 minute presentation to the MIT
          community and relevant stakeholders including other organizations that are working to recover
          lobster pots. Additionally, we presented a poster at the annual MIT DeFlorez Design Competition.
        </p>
      </section>

      <!-- System Capabilities -->
      <section>
        <h2>System Capabilities</h2>
        <ul>
          <li>GPS waypoint navigation and manual control using QGroundControl + ArduPilot</li>
          <li>3m accuracy USBL tracking + IMU fusion</li>
          <li>Short-range localization using sonar and camera</li>
          <li>Mechanical disengagement system for emergency detachment</li>
        </ul>
      </section>

      <!-- Architecture -->
      <section class="two-col">
        <div>
          <h2>Architecture</h2>

          <p class="arch-summary">
            This system combines surface control software, acoustic positioning,
            and onboard networking to support teleoperation and state estimation
            for an underwater ROV.
          </p>

          <ul class="arch-list">
            <li><strong>Operator input:</strong> QGroundControl with custom control logic</li>
            <li><strong>Positioning:</strong> USBL-based external localization</li>
            <li><strong>Onboard compute:</strong> Raspberry Pi running BlueOS</li>
            <li><strong>Low-level control:</strong> Dedicated navigation board</li>
          </ul>
        </div>

        <div class="diagram-card">
          <img
            src={`${import.meta.env.BASE_URL}projects/2017/architecture.png`}
            alt="ROV system architecture diagram showing surface control, USBL positioning, and onboard compute"
            loading="lazy"
          />
          <p class="diagram-caption">
            Surface control, USBL-based positioning, and onboard communication stack.
          </p>
        </div>
      </section>

      <section class="project-section">
        <h2>System Demonstration</h2>

        <div class="video-wrap">
      
        <video
        class="lazy-video"
        controls
        playsinline
        preload="none"
        muted
        data-src={`${import.meta.env.BASE_URL}projects/2017/demo.mp4`}
        type="video/mp4" 
        poster={`${import.meta.env.BASE_URL}projects/2017/demo-poster.png`}
        >
        Sorry, your browser doesn’t support embedded videos.
        </video>


        <p class="caption">
            30-second field test showing ROV approach, hook engagement, and recovery.
        </p>
        </div>

        </section>


      <!-- Mission Flow -->
      <section class="proj-section" id="mission-flow" aria-label="Mission flow">
        <div class="proj-section-head">
          <h2 class="proj-h2">Mission Flow</h2>
          <p class="proj-lede">
            High-level functional flow for the ROV pot retrieval sequence, from launch to recovery.
          </p>
        </div>

        <div class="proj-two-col">
          <div class="proj-copy">
            <p>
              We organized the end-to-end operation as a modular sequence of steps
              (navigate → locate → hook → winch → detach → recover). The diagram captures the
              intended control flow and key decision points for a full deployment.
            </p>

            <ul class="proj-bullets">
              <li><strong>Navigation + approach:</strong> move to the target area and confirm position.</li>
              <li><strong>Target acquisition:</strong> use onboard sensing to locate the pot.</li>
              <li><strong>Manipulation + recovery:</strong> hook, winch, and safely detach/recover.</li>
            </ul>
          </div>

          <div class="diagram-card">
            <img
              src={`${import.meta.env.BASE_URL}projects/2017/fbd.png`}
              alt="Functional flow block diagram of the ROV pot retrieval sequence"
              loading="lazy"
            />
            <p class="diagram-caption">
              Functional flow block diagram for the pot retrieval sequence.
            </p>
          </div>
        </div>
      </section>

      <!-- Engineering Constraints -->
      <section class="proj-section">
        <h2 class="proj-h2">Engineering Constraints & Lessons</h2>

        <p class="proj-lede">
          Pool and tank testing exposed several real-world constraints that shaped both system design and evaluation.
        </p>

        <ul class="proj-bullets">
          <li>
            <strong>Sensor limitations:</strong> DVL performance was unstable in confined, reflective environments,
            leading to drift and thermal issues during extended runs.
          </li>
          <li>
            <strong>Localization constraints:</strong> Indoor testing limited GPS availability, requiring
            frequent operator intervention and conservative state estimation.
          </li>
          <li>
            <strong>System integration issues:</strong> Communication conflicts between software components
            occasionally blocked control pipelines.
          </li>
          <li>
            <strong>Hardware reliability:</strong> Intermittent sensor, thruster, and wiring failures emphasized
            the need for modular debugging and fault isolation.
          </li>
        </ul>

        <p class="proj-note">
          These constraints motivated a more defensive system design and informed how we approached testing,
          monitoring, and recovery behaviors in later iterations.
        </p>
      </section>

      <!-- Key Takeaways -->
      <section class="proj-section">
        <h2 class="proj-h2">Key Takeaways</h2>

        <p>
          Although time and hardware constraints limited a full autonomous demonstration,
          this project provided valuable experience in underwater systems, sensor integration,
          and real-world debugging.
        </p>

        <p>
          We made meaningful progress on embedded communication pipelines, hook deployment logic,
          and USBL-based localization, and gained a deeper appreciation for how environmental
          conditions shape system behavior.
        </p>

        <p class="proj-note">
          Most importantly, the project reinforced the importance of validating autonomy in
          realistic settings and designing electromechanical systems that remain robust under
          uncertainty.
        </p>
      </section>

      <!-- Future Work -->
      <section class="proj-section">
        <h2 class="proj-h2">Future Work</h2>
        <p>
          For future development, we recommended simulation-based control tuning (e.g., SITL for BlueRobotics),
          streamlined navigation software to avoid using multiple programs at once, and improved tether/recovery
          mechanisms to minimize drift and enable deep-sea operation.
        </p>
      </section>
    </article>
  </section>
</Layout>

<script is:inline>
(() => {
  const root = document.querySelector("[data-gallery]");
  if (!root) return;

  const track = root.querySelector(".gallery-track");
  const slides = [...root.querySelectorAll(".gallery-slide")];
  const prev = root.querySelector("[data-prev]");
  const next = root.querySelector("[data-next]");
  const dotsWrap = root.querySelector("[data-dots]");

  if (!track || slides.length === 0) return;

  let idx = 0;

  function setActiveDot() {
    if (!dotsWrap) return;
    [...dotsWrap.children].forEach((d, j) => d.toggleAttribute("data-active", j === idx));
  }

  function snapTo(i) {
    idx = (i + slides.length) % slides.length;

    // Prevent vertical jump by forcing "block: nearest"
    slides[idx].scrollIntoView({
      behavior: "smooth",
      inline: "start",
      block: "nearest",
    });

    setActiveDot();
  }

  if (dotsWrap) {
    dotsWrap.innerHTML = "";
    slides.forEach((_, i) => {
      const b = document.createElement("button");
      b.type = "button";
      b.className = "gallery-dot";
      b.addEventListener("click", (e) => {
        e.preventDefault();
        snapTo(i);
      });
      dotsWrap.appendChild(b);
    });
  }

  prev?.addEventListener("click", (e) => {
    e.preventDefault();
    snapTo(idx - 1);
  });

  next?.addEventListener("click", (e) => {
    e.preventDefault();
    snapTo(idx + 1);
  });

  // When the gallery is focused, use arrow keys to navigate WITHOUT scrolling the page
  root.addEventListener("keydown", (e) => {
    if (e.key === "ArrowLeft") {
      e.preventDefault();
      snapTo(idx - 1);
    } else if (e.key === "ArrowRight") {
      e.preventDefault();
      snapTo(idx + 1);
    }
  });

  // Make sure the gallery can receive keyboard focus
  if (!root.hasAttribute("tabindex")) root.setAttribute("tabindex", "0");

  snapTo(0);

    const videos = document.querySelectorAll("video.lazy-video[data-src]");
    if (!videos.length) return;

    const loadVideo = (video) => {
      const src = video.dataset.src;
      if (!src) return;
      video.src = src;
      video.removeAttribute("data-src");
      // video.load(); // optional; setting src usually triggers load
    };

    if (!("IntersectionObserver" in window)) {
      videos.forEach(loadVideo);
      return;
    }

    const io = new IntersectionObserver((entries) => {
      entries.forEach((entry) => {
        if (!entry.isIntersecting) return;
        loadVideo(entry.target);
        io.unobserve(entry.target);
      });
    }, { rootMargin: "200px 0px" }); // starts loading slightly before it appears

    videos.forEach(v => io.observe(v));
})();
</script>